,Name,Author,Abstract,Download link
0,Copying Machine Learning Classifiers,"['Irene Unceta', 'Jordi Nin', 'Oriol Pujol']","We study model-agnostic copies of machine learning classifiers. We develop the theory behind the problem of copying, highlighting its differences with that of learning, and propose a framework to copy the functionality of any classifier using no prior knowledge of its parameters or training data distribution. We identify the different sources of loss and provide guidelines on how best to generate synthetic sets for the copying process. We further introduce a set of metrics to evaluate copies in practice. We validate our framework through extensive experiments using data from a series of well-known problems. We demonstrate the value of copies in use cases where desiderata such as interpretability, fairness or productivization constrains need to be addressed. Results show that copies can be exploited to enhance existing solutions and improve them adding new features and characteristics.
        ? Less",https://arxiv.org/pdf/1903.01879
1,Extreme Learning Machine-Based Receiver for MIMO LED Communications,"['Dawei Gao', 'Qinghua Guo']","This work concerns receiver design for light-emitting diode (LED) multiple input multiple output (MIMO) communications where the LED nonlinearity can severely degrade the performance of communications. In this paper, we propose an extreme learning machine (ELM) based receiver to jointly handle the LED nonlinearity and cross-LED interference, and a circulant input weight matrix is employed, which significantly reduces the complexity of the receiver with the fast Fourier transform (FFT). It is demonstrated that the proposed receiver can efficiently handle the LED nonlinearity and cross-LED interference.
        ? Less",https://arxiv.org/pdf/1903.01551
2,A Machine Learning-Based Detection Technique for Optical Fiber Nonlinearity Mitigation,"['Abdelkerim Amari', 'Xiang Lin', 'Octavia A. Dobre', 'Ramachandran Venkatesan', 'Alex Alvarado']","We investigate the performance of a machine learning classification technique, called the Parzen window, to mitigate the fiber nonlinearity in the context of dispersion managed and dispersion unmanaged systems. The technique is applied for detection at the receiver side, and deals with the non-Gaussian nonlinear effects by designing improved decision boundaries. We also propose a two-stage mitigation technique using digital back propagation and Parzen window for dispersion unmanaged systems. In this case, digital back propagation compensates for the deterministic nonlinearity and the Parzen window deals with the stochastic nonlinear signal-noise interactions, which are not taken into account by digital back propagation. A performance improvement up to 0:4 dB in terms of Q factor is observed.
        ? Less",https://arxiv.org/pdf/1903.01549
3,A Machine Learning Artificial Neural Network Calibration of the Strong-Line Oxygen Abundance,['I-Ting Ho'],"The HII region oxygen abundance is a key observable for studying chemical properties of galaxies. Deriving oxygen abundances using optical spectra often relies on empirical strong-line calibrations calibrated to the direct method. Existing calibrations usually adopt linear or polynomial functions to describe the non-linear relationships between strong line ratios and Te oxygen abundances. Here, I explore the possibility of using an artificial neural network model to construct a non-linear strong-line calibration. Using about 950 literature HII region spectra with auroral line detections, I build multi-layer perceptron models under the machine learning framework of training and testing. I show that complex models, like the neural network, are preferred at the current sample size and can better predict oxygen abundance than simple linear models. I demonstrate that the new calibration can reproduce metallicity gradients in nearby galaxies and the mass-metallicity relationship. Finally, I discuss the prospects of developing new neural network calibrations using forthcoming large samples of HII region and also the challenges faced.
        ? Less",https://arxiv.org/pdf/1903.01506
4,Traditional Machine Learning for Pitch Detection,"['Thomas Drugman', 'Goeric Huybrechts', 'Viacheslav Klimkov', 'Alexis Moinet']","Pitch detection is a fundamental problem in speech processing as F0 is used in a large number of applications. Recent articles have proposed deep learning for robust pitch tracking. In this paper, we consider voicing detection as a classification problem and F0 contour estimation as a regression problem. For both tasks, acoustic features from multiple domains and traditional machine learning methods are used. The discrimination power of existing and proposed features is assessed through mutual information. Multiple supervised and unsupervised approaches are compared. A significant relative reduction of voicing errors over the best baseline is obtained: 20% with the best clustering method (K-means) and 45% with a Multi-Layer Perceptron. For F0 contour estimation, the benefits of regression techniques are limited though. We investigate whether those objective gains translate in a parametric synthesis task. Clear perceptual preferences are observed for the proposed approach over two widely-used baselines (RAPT and DIO).
        ? Less",https://arxiv.org/pdf/1903.01290
5,Reconstruction of Hydraulic Data by Machine Learning,"['Corentin J. Lapeyre', 'Nicolas Cazard', 'Pamphile T. Roy', 'Sophie Ricci', 'Fabrice Zaoui']","Numerical simulation models associated with hydraulic engineering take a wide array of data into account to produce predictions: rainfall contribution to the drainage basin (characterized by soil nature, infiltration capacity and moisture), current water height in the river, topography, nature and geometry of the river bed, etc. This data is tainted with uncertainties related to an imperfect knowledge of the field, measurement errors on the physical parameters calibrating the equations of physics, an approximation of the latter, etc. These uncertainties can lead the model to overestimate or underestimate the flow and height of the river. Moreover, complex assimilation models often require numerous evaluations of physical solvers to evaluate these uncertainties, limiting their use for some real-time operational applications. In this study, we explore the possibility of building a predictor for river height at an observation point based on drainage basin time series data. An array of data-driven techniques is assessed for this task, including statistical models, machine learning techniques and deep neural network approaches. These are assessed on several metrics, offering an overview of the possibilities related to hydraulic time-series. An important finding is that for the same hydraulic quantity, the best predictors vary depending on whether the data is produced using a physical model or real observations.
        ? Less",https://arxiv.org/pdf/1903.01123
6,Wall effects of eccentric spheres machine learning for convenient computation,"['Lachlan J. Gibson', 'Shu Zhang', 'Alexander B. Stilgoe', 'Timo A. Nieminen', 'Halina Rubinsztein-Dunlop']","In confined systems, such as the inside of a biological cell, the outer boundary or wall can affect the dynamics of internal particles. In many cases of interest both the internal particle and outer wall are approximately spherical. Therefore, quantifying the wall effects from an outer spherical boundary on the motion of an internal eccentric sphere is very useful. However, when the two spheres are not concentric, the problem becomes non-trivial. In this paper we improve existing analytical methods to evaluate these wall effects and then train a feed-forward artificial neural network within a broader model. The final model generally performed with \sim 0.001\%\sim 0.001\% error within the training domain and \sim 0.05\%\sim 0.05\% when the outer spherical wall was extrapolated to an infinite plane. Through this model, the wall effects of an outer spherical boundary on the arbitrary motion of an internal sphere for all experimentally achievable configurations can now be conveniently and efficiently determined.
        ? Less",https://arxiv.org/pdf/1903.01040
7,Machine Learning Holographic Mapping by Neural Network Renormalization Group,"['Hong-Ye Hu', 'Shuo-Hui Li', 'Lei Wang', 'Yi-Zhuang You']","We develop the neural network renormalization group as a model-independent approach to design general forms of exact holographic mapping (EHM) for interacting field theories. The EHM constitutes a bijection that maps a conformal field theory (CFT) on the holographic boundary to a gapped field theory in the holographic bulk, aiming to reduce the mutual information in the bulk filed. We design a flow-based hierarchical deep generative neural network as a variational realization of the EHM. Given the CFT action, we first train the neural network to find the optimal EHM by assuming the bulk field as independent random variables. We then use the trained EHM to map the CFT back to a bulk effective action, from which the holographic bulk geometry can be measured from the residual mutual information in the bulk field. We apply this approach to the complex ?^4?^4 theory in two-dimensional Euclidian spacetime, and show that the holographic bulk matches the three-dimensional hyperbolic geometry.
        ? Less",https://arxiv.org/pdf/1903.00804
8,A unifying representer theorem for inverse problems and machine learning,['Michael Unser'],"The standard approach for dealing with the ill-posedness of the training problem in machine learning and/or the reconstruction of a signal from a limited number of measurements is regularization. The method is applicable whenever the problem is formulated as an optimization task. The standard strategy consists in augmenting the original cost functional by an energy that penalizes solutions with undesirable behavior. The effect of regularization is very well understood when the penalty involves a Hilbertian norm. Another popular configuration is the use of an \ell_1\ell_1-norm (or some variant thereof) that favors sparse solutions. In this paper, we propose a higher-level formulation of regularization within the context of Banach spaces. We present a general representer theorem that characterizes the solutions of a remarkably broad class of optimization problems. We then use our theorem to retrieve a number of known results in the literature---e.g., the celebrated representer theorem of machine leaning for RKHS, Tikhonov regularization, representer theorems for sparsity promoting functionals, the recovery of spikes---as well as a few new ones.
        ? Less",https://arxiv.org/pdf/1903.00687
9,Single-Component Order Parameter in URu_2_2Si_2_2 Uncovered by Resonant Ultrasound Spectroscopy and Machine Learning,"['Sayak Ghosh', 'Michael Matty', 'Ryan Baumbach', 'Eric D. Bauer', 'K. A. Modic', 'Arkady Shekhter', 'J. A. Mydosh', 'Eun-Ah Kim', 'B. J. Ramshaw']","URu_2_2Si_2_2 exhibits a clear phase transition at T_{HO}= 17.5~_{HO}= 17.5~K to a low-temperature phase known as ""hidden order"" (HO). Even the most basic information needed to construct a theory of this state---such as the number of components in the order parameter---has been lacking. Here we use resonant ultrasound spectroscopy (RUS) and machine learning to determine that the order parameter of HO is one-dimensional (singlet), ruling out a large class of theories based on two-dimensional (doublet) order parameters. This strict constraint is independent of any microscopic mechanism, and independent of other symmetries that HO may break. Our technique is general for second-order phase transitions, and can discriminate between nematic (singlet) versus loop current (doublet) order in the high-\Tc cuprates, and conventional (singlet) versus the proposed p_x+ip_yp_x+ip_y (doublet) superconductivity in Sr_2_2RuO_4_4. The machine learning framework we develop should be readily adaptable to other spectroscopic techniques where missing resonances confound traditional analysis, such as NMR.
        ? Less",https://arxiv.org/pdf/1903.00552
10,Machine learning in policy evaluation: new tools for causal inference,"['Noemi Kreif', 'Karla DiazOrdaz']","While machine learning (ML) methods have received a lot of attention in recent years, these methods are primarily for prediction. Empirical researchers conducting policy evaluations are, on the other hand, pre-occupied with causal problems, trying to answer counterfactual questions: what would have happened in the absence of a policy? Because these counterfactuals can never be directly observed (described as the ""fundamental problem of causal inference"") prediction tools from the ML literature cannot be readily used for causal inference. In the last decade, major innovations have taken place incorporating supervised ML tools into estimators for causal parameters such as the average treatment effect (ATE). This holds the promise of attenuating model misspecification issues, and increasing of transparency in model selection. One particularly mature strand of the literature include approaches that incorporate supervised ML approaches in the estimation of the ATE of a binary treatment, under the \textit{unconfoundedness} and positivity assumptions (also known as exchangeability and overlap assumptions).
  This article reviews popular supervised machine learning algorithms, including the Super Learner. Then, some specific uses of machine learning for treatment effect estimation are introduced and illustrated, namely (1) to create balance among treated and control groups, (2) to estimate so-called nuisance models (e.g. the propensity score, or conditional expectations of the outcome) in semi-parametric estimators that target causal parameters (e.g. targeted maximum likelihood estimation or the double ML estimator), and (3) the use of machine learning for variable selection in situations with a high number of covariates.
        ? Less",https://arxiv.org/pdf/1903.00402
11,Continuous Integration of Machine Learning Models with ease.ml/ci: Towards a Rigorous Yet Practical Treatment,"['Cedric Renggli', 'Bojan Karlaš', 'Bolin Ding', 'Feng Liu', 'Kevin Schawinski', 'Wentao Wu', 'Ce Zhang']","Continuous integration is an indispensable step of modern software engineering practices to systematically manage the life cycles of system development. Developing a machine learning model is no difference - it is an engineering process with a life cycle, including design, implementation, tuning, testing, and deployment. However, most, if not all, existing continuous integration engines do not support machine learning as first-class citizens.
  In this paper, we present ease.ml/ci, to our best knowledge, the first continuous integration system for machine learning. The challenge of building ease.ml/ci is to provide rigorous guarantees, e.g., single accuracy point error tolerance with 0.999 reliability, with a practical amount of labeling effort, e.g., 2K labels per test. We design a domain specific language that allows users to specify integration conditions with reliability constraints, and develop simple novel optimizations that can lower the number of labels required by up to two orders of magnitude for test conditions popularly used in real production systems.
        ? Less",https://arxiv.org/pdf/1903.00278
12,Identifying Bid Leakage In Procurement Auctions: Machine Learning Approach,"['Dmitry I. Ivanov', 'Alexander S. Nesterov']","We propose a novel machine-learning-based approach to detect bid leakage in first-price sealed-bid auctions. We extract and analyze the data on more than 1.4 million Russian procurement auctions between 2014 and 2018. As bid leakage in each particular auction is tacit, the direct classification is impossible. Instead, we reduce the problem of bid leakage detection to Positive-Unlabeled Classification. The key idea is to regard the losing participants as fair and the winners as possibly corrupted. This allows us to estimate the prior probability of bid leakage in the sample, as well as the posterior probability of bid leakage for each specific auction. We find that at least 16\% of auctions are exposed to bid leakage. Bid leakage is more likely in auctions with a higher reserve price, lower number of bidders and lower price fall, and where the winning bid is received in the last hour before the deadline.
        ? Less",https://arxiv.org/pdf/1903.00261
13,Completing density functional theory by machine-learning hidden messages from molecules,"['Ryo Nagai', 'Ryosuke Akashi', 'Osamu Sugino']","Kohn-Sham(KS) density functional theory(DFT) is the base of modern computational approaches to electronic structures. Their accuracy vitally relies on the exchange-correlation energy functional, where all the electron-electron interaction beyond the classical Coulomb one are encapsulated. Improving the functional has long been the major topic of DFT but the past approaches remain heuristic rather than systematic. Here we demonstrate a systematic way to machine-learn the functional from accurate density and energy calculated for a few molecules. After relating the density and energy with a flexible feed-forward neural network, the network is optimized to reproduce the accurate ones within KS-DFT, of which the exchange-correlation potential is obtained by taking functional derivatives with a help of the back-propagation method. The machine-learnt functionals show comparable or improved accuracies to the existing ones. In addition, one can naturally extend the scheme to a non-local one by simply adding the nodes connected to the hidden layers, thus allowing to construct various functionals of different accuracy and complexity. This novel approach thus paves a way to enriching the DFT framework by utilizing the rapidly advancing machine learning techniques.
        ? Less",https://arxiv.org/pdf/1903.00238
14,Optimal Algorithms for Ski Rental with Soft Machine-Learned Predictions,['Rohan Kodialam'],"We consider a variant of the classic Ski Rental online algorithm with applications to machine learning. In our variant, we allow the skier access to a black-box machine-learning algorithm that provides an estimate of the probability that there will be at most a threshold number of ski-days. We derive a class of optimal randomized algorithms to determine the strategy that minimizes the worst-case expected competitive ratio for the skier given a prediction from the machine learning algorithm,and analyze the performance and robustness of these algorithms.
        ? Less",https://arxiv.org/pdf/1903.00092
15,Reinforcement Learning based Curriculum Optimization for Neural Machine Translation,"['Gaurav Kumar', 'George Foster', 'Colin Cherry', 'Maxim Krikun']","We consider the problem of making efficient use of heterogeneous training data in neural machine translation (NMT). Specifically, given a training dataset with a sentence-level feature such as noise, we seek an optimal curriculum, or order for presenting examples to the system during training. Our curriculum framework allows examples to appear an arbitrary number of times, and thus generalizes data weighting, filtering, and fine-tuning schemes. Rather than relying on prior knowledge to design a curriculum, we use reinforcement learning to learn one automatically, jointly with the NMT system, in the course of a single training run. We show that this approach can beat uniform and filtering baselines on Paracrawl and WMT English-to-French datasets by up to +3.4 BLEU, and match the performance of a hand-designed, state-of-the-art curriculum.
        ? Less",https://arxiv.org/pdf/1903.00041
16,"The principles of adaptation in organisms and machines I: machine learning, information theory, and thermodynamics",['Hideaki Shimazaki'],"How do organisms recognize their environment by acquiring knowledge about the world, and what actions do they take based on this knowledge? This article examines hypotheses about organisms' adaptation to the environment from machine learning, information-theoretic, and thermodynamic perspectives. We start with constructing a hierarchical model of the world as an internal model in the brain, and review standard machine learning methods to infer causes by approximately learning the model under the maximum likelihood principle. This in turn provides an overview of the free energy principle for an organism, a hypothesis to explain perception and action from the principle of least surprise. Treating this statistical learning as communication between the world and brain, learning is interpreted as a process to maximize information about the world. We investigate how the classical theories of perception such as the infomax principle relates to learning the hierarchical model. We then present an approach to the recognition and learning based on thermodynamics, showing that adaptation by causal learning results in the second law of thermodynamics whereas inference dynamics that fuses observation with prior knowledge forms a thermodynamic process. These provide a unified view on the adaptation of organisms to the environment.
        ? Less",https://arxiv.org/pdf/1902.11233
17,Learning Everywhere: Pervasive Machine Learning for Effective High-Performance Computation,"['Geoffrey Fox', 'James A. Glazier', 'JCS Kadupitiya', 'Vikram Jadhao', 'Minje Kim', 'Judy Qiu', 'James P. Sluka', 'Endre Somogyi', 'Madhav Marathe', 'Abhijin Adiga', 'Jiangzhuo Chen', 'Oliver Beckstein', 'Shantenu Jha']","The convergence of HPC and data-intensive methodologies provide a promising approach to major performance improvements. This paper provides a general description of the interaction between traditional HPC and ML approaches and motivates the Learning Everywhere paradigm for HPC. We introduce the concept of effective performance that one can achieve by combining learning methodologies with simulation-based approaches, and distinguish between traditional performance as measured by benchmark scores. To support the promise of integrating HPC and learning methods, this paper examines specific examples and opportunities across a series of domains. It concludes with a series of open computer science and cyberinfrastructure questions and challenges that the Learning Everywhere paradigm presents.
        ? Less",https://arxiv.org/pdf/1902.10810
18,A Replication Study: Machine Learning Models Are Capable of Predicting Sexual Orientation From Facial Images,['John Leuner'],"Recent research used machine learning methods to predict a person's sexual orientation from their photograph (Wang and Kosinski, 2017). To verify this result, two of these models are replicated, one based on a deep neural network (DNN) and one on facial morphology (FM). Using a new dataset of 20,910 photographs from dating websites, the ability to predict sexual orientation is confirmed (DNN accuracy male 68%, female 77%, FM male 62%, female 72%). To investigate whether facial features such as brightness or predominant colours are predictive of sexual orientation, a new model based on highly blurred facial images was created. This model was also able to predict sexual orientation (male 63%, female 72%). The tested models are invariant to intentional changes to a subject's makeup, eyewear, facial hair and head pose (angle that the photograph is taken at). It is shown that the head pose is not correlated with sexual orientation. While demonstrating that dating profile images carry rich information about sexual orientation these results leave open the question of how much is determined by facial morphology and how much by differences in grooming, presentation and lifestyle. The advent of new technology that is able to detect sexual orientation in this way may have serious implications for the privacy and safety of gay men and women.
        ? Less",https://arxiv.org/pdf/1902.10739
19,Shallow Water Bathymetry Mapping from UAV Imagery based on Machine Learning,"['Panagiotis Agrafiotis', 'Dimitrios Skarlatos', 'Andreas Georgopoulos', 'Konstantinos Karantzalos']","The determination of accurate bathymetric information is a key element for near offshore activities, hydrological studies such as coastal engineering applications, sedimentary processes, hydrographic surveying as well as archaeological mapping and biological research. UAV imagery processed with Structure from Motion (SfM) and Multi View Stereo (MVS) techniques can provide a low-cost alternative to established shallow seabed mapping techniques offering as well the important visual information. Nevertheless, water refraction poses significant challenges on depth determination. Till now, this problem has been addressed through customized image-based refraction correction algorithms or by modifying the collinearity equation. In this paper, in order to overcome the water refraction errors, we employ machine learning tools that are able to learn the systematic underestimation of the estimated depths. In the proposed approach, based on known depth observations from bathymetric LiDAR surveys, an SVR model was developed able to estimate more accurately the real depths of point clouds derived from SfM-MVS procedures. Experimental results over two test sites along with the performed quantitative validation indicated the high potential of the developed approach.
        ? Less",https://arxiv.org/pdf/1902.10733
20,Social Credibility Incorporating Semantic Analysis and Machine Learning: A Survey of the State-of-the-Art and Future Research Directions,"['Bilal Abu-Salih', 'Bushra Bremie', 'Pornpit Wongthongtham', 'Kevin Duan', 'Tomayess Issa', 'Kit Yan Chan', 'Mohammad Alhabashneh', 'Teshreen Albtoush', 'Sulaiman Alqahtani', 'Abdullah Alqahtani', 'Muteeb Alahmari', 'Naser Alshareef', 'Abdulaziz Albahlal']","The wealth of Social Big Data (SBD) represents a unique opportunity for organisations to obtain the excessive use of such data abundance to increase their revenues. Hence, there is an imperative need to capture, load, store, process, analyse, transform, interpret, and visualise such manifold social datasets to develop meaningful insights that are specific to an application domain. This paper lays the theoretical background by introducing the state-of-the-art literature review of the research topic. This is associated with a critical evaluation of the current approaches, and fortified with certain recommendations indicated to bridge the research gap.
        ? Less",https://arxiv.org/pdf/1902.10402
21,"When Relaxations Go Bad: ""Differentially-Private"" Machine Learning","['Bargav Jayaraman', 'David Evans']","Differential privacy is becoming a standard notion for performing privacy-preserving machine learning over sensitive data. It provides formal guarantees, in terms of the privacy budget, ??, on how much information about individual training records is leaked by the model. While the privacy budget is directly correlated to the privacy leakage, the calibration of the privacy budget is not well understood. As a result, many existing works on privacy-preserving machine learning select large values of ?? in order to get acceptable utility of the model, with little understanding of the concrete impact of such choices on meaningful privacy. Moreover, in scenarios where iterative learning procedures are used which require privacy guarantees for each iteration, relaxed definitions of differential privacy are often used which further tradeoff privacy for better utility. In this paper, we evaluate the impacts of these choices on privacy in experiments with logistic regression and neural network models. We quantify the privacy leakage in terms of advantage of the adversary performing inference attacks and by analyzing the number of members at risk for exposure. Our main findings are that current mechanisms for differential privacy for machine learning rarely offer acceptable utility-privacy tradeoffs: settings that provide limited accuracy loss provide little effective privacy, and settings that provide strong privacy result in useless models. Open source code is available at https://github.com/bargavj/EvaluatingDPML.
        ? Less",https://arxiv.org/pdf/1902.08874
22,Inference of a Multi-Domain Machine Learning Model to Predict Mortality in Hospital Stays for Patients with Cancer upon Febrile Neutropenia Onset,"['Xinsong Du', 'Jae Min', 'Mattia Prosperi', 'Rohit Bishnoi', 'Dominick J. Lemas', 'Chintan P. Shah']","Febrile neutropenia (FN) has been associated with high mortality, especially among adults with cancer. Understanding the patient and provider level heterogeneity in FN hospital admissions has potential to inform personalized interventions focused on increasing survival of individuals with FN. We leverage machine learning techniques to disentangling the complex interactions among multi domain risk factors in a population with FN. Data from the Healthcare Cost and Utilization Project (HCUP) National Inpatient Sample and Nationwide Inpatient Sample (NIS) were used to build machine learning based models of mortality for adult cancer patients who were diagnosed with FN during a hospital admission. In particular, the importance of risk factors from different domains (including demographic, clinical, and hospital associated information) was studied. A set of more interpretable (decision tree, logistic regression) as well as more black box (random forest, gradient boosting, neural networks) models were analyzed and compared via multiple cross validation. Our results demonstrate that a linear prediction score of FN mortality among adults with cancer, based on admission information is effective in classifying high risk patients; clinical diagnoses is the domain with the highest predictive power. A number of the risk variables (e.g. sepsis, kidney failure, etc.) identified in this study are clinically actionable and may inform future studies looking at the patients prior medical history are warranted.
        ? Less",https://arxiv.org/pdf/1902.07839
23,Automating the Construction of Jet Observables with Machine Learning,"['Kaustuv Datta', 'Andrew Larkoski', 'Benjamin Nachman']","Machine-learning assisted jet substructure tagging techniques have the potential to significantly improve searches for new particles and Standard Model measurements in hadronic final states. Techniques with simple analytic forms are particularly useful for establishing robustness and gaining physical insight. We introduce a procedure to automate the construction of a large class of observables that are chosen to completely specify MM-body phase space. The procedure is validated on the task of distinguishing H\rightarrow b\bar{b}H\rightarrow b\bar{b} from g\rightarrow b\bar{b}g\rightarrow b\bar{b}, where M=3M=3 and previous brute-force approaches to construct an optimal product observable for the MM-body phase space have established the baseline performance. We then use the new method to design tailored observables for the boosted Z'Z' search, where M=4M=4 and brute-force methods are intractable. The new classifiers outperform standard 22-prong tagging observables, illustrating the power of the new optimization method for improving searches and measurement at the LHC and beyond.
        ? Less",https://arxiv.org/pdf/1902.07180
24,TensorFlow.js: Machine Learning for the Web and Beyond,"['Daniel Smilkov', 'Nikhil Thorat', 'Yannick Assogba', 'Ann Yuan', 'Nick Kreeger', 'Ping Yu', 'Kangyi Zhang', 'Shanqing Cai', 'Eric Nielsen', 'David Soergel', 'Stan Bileschi', 'Michael Terry', 'Charles Nicholson', 'Sandeep N. Gupta', 'Sarah Sirajuddin', 'D. Sculley', 'Rajat Monga', 'Greg Corrado', 'Fernanda B. Viégas', 'Martin Wattenberg']","TensorFlow.js is a library for building and executing machine learning algorithms in JavaScript. TensorFlow.js models run in a web browser and in the Node.js environment. The library is part of the TensorFlow ecosystem, providing a set of APIs that are compatible with those in Python, allowing models to be ported between the Python and JavaScript ecosystems. TensorFlow.js has empowered a new set of developers from the extensive JavaScript community to build and deploy machine learning models and enabled new classes of on-device computation. This paper describes the design, API, and implementation of TensorFlow.js, and highlights some of the impactful use cases.
        ? Less",https://arxiv.org/pdf/1901.05350
25,Towards a topological-geometrical theory of group equivariant non-expansive operators for data analysis and machine learning,"['Mattia G. Bergomi', 'Patrizio Frosini', 'Daniela Giorgi', 'Nicola Quercioli']","The aim of this paper is to provide a general mathematical framework for group equivariance in the machine learning context. The framework builds on a synergy between persistent homology and the theory of group actions. We define group-equivariant non-expansive operators (GENEOs), which are maps between function spaces associated with groups of transformations. We study the topological and metric properties of the space of GENEOs to evaluate their approximating power and set the basis for general strategies to initialise and compose operators. We begin by defining suitable pseudo-metrics for the function spaces, the equivariance groups, and the set of non-expansive operators. Basing on these pseudo-metrics, we prove that the space of GENEOs is compact and convex, under the assumption that the function spaces are compact and convex. These results provide fundamental guarantees in a machine learning perspective. We show examples on the MNIST and fashion-MNIST datasets. By considering isometry-equivariant non-expansive operators, we describe a simple strategy to select and sample operators, and show how the selected and sampled operators can be used to perform both classical metric learning and an effective initialisation of the kernels of a convolutional neural network.
        ? Less",https://arxiv.org/pdf/1812.11832
26,Graph Networks as a Universal Machine Learning Framework for Molecules and Crystals,"['Chi Chen', 'Weike Ye', 'Yunxing Zuo', 'Chen Zheng', 'Shyue Ping Ong']","Graph networks are a new machine learning (ML) paradigm that supports both relational reasoning and combinatorial generalization. Here, we develop universal MatErials Graph Network (MEGNet) models for accurate property prediction in both molecules and crystals. We demonstrate that the MEGNet models outperform prior ML models such as the SchNet in 11 out of 13 properties of the QM9 molecule data set. Similarly, we show that MEGNet models trained on \sim 60,000\sim 60,000 crystals in the Materials Project substantially outperform prior ML models in the prediction of the formation energies, band gaps and elastic moduli of crystals, achieving better than DFT accuracy over a much larger data set. We present two new strategies to address data limitations common in materials science and chemistry. First, we demonstrate a physically-intuitive approach to unify four separate molecular MEGNet models for the internal energy at 0 K and room temperature, enthalpy and Gibbs free energy into a single free energy MEGNet model by incorporating the temperature, pressure and entropy as global state inputs. Second, we show that the learned element embeddings in MEGNet models encode periodic chemical trends and can be transfer-learned from a property model trained on a larger data set (formation energies) to improve property models with smaller amounts of data (band gaps and elastic moduli).
        ? Less",https://arxiv.org/pdf/1812.05055
27,sGDML: Constructing Accurate and Data Efficient Molecular Force Fields Using Machine Learning,"['Stefan Chmiela', 'Huziel E. Sauceda', 'Igor Poltavsky', 'Klaus-Robert Müller', 'Alexandre Tkatchenko']","We present an optimized implementation of the recently proposed symmetric gradient domain machine learning (sGDML) model. The sGDML model is able to faithfully reproduce global potential energy surfaces (PES) for molecules with a few dozen atoms from a limited number of user-provided reference molecular conformations and the associated atomic forces. Here, we introduce a Python software package to reconstruct and evaluate custom sGDML force fields (FFs), without requiring in-depth knowledge about the details of the model. A user-friendly command-line interface offers assistance through the complete process of model creation, in an effort to make this novel machine learning approach accessible to broad practitioners. Our paper serves as a documentation, but also includes a practical application example of how to reconstruct and use a PBE0+MBD FF for paracetamol. Finally, we show how to interface sGDML with the FF simulation engines ASE (Larsen et al., J. Phys. Condens. Matter 29, 273002 (2017)) and i-PI (Kapil et al., Comput. Phys. Commun. 236, 214-223 (2019)) to run numerical experiments, including structure optimization, classical and path integral molecular dynamics and nudged elastic band calculations.
        ? Less",https://arxiv.org/pdf/1812.04986
28,A hybrid machine-learning algorithm for designing quantum experiments,"[""L. O'Driscoll"", 'R. Nichols', 'P. A. Knott']","We introduce a hybrid machine-learning algorithm for designing quantum optics experiments that produce specific quantum states. Our algorithm successfully found experimental schemes to produce all 5 states we asked it to, including Schrödinger cat states and cubic phase states, all to a fidelity of over 96\%96\%. Here we specifically focus on designing realistic experiments, and hence all of the algorithm's designs only contain experimental elements that are available with current technology. The core of our algorithm is a genetic algorithm that searches for optimal arrangements of the experimental elements, but to speed up the initial search we incorporate a neural network that classifies quantum states. The latter is of independent interest, as it quickly learned to accurately classify quantum states given their photon-number distributions.
        ? Less",https://arxiv.org/pdf/1812.03183
29,Finding Black Holes with Black Boxes -- Using Machine Learning to Identify Globular Clusters with Black Hole Subsystems,"['Ammar Askar', 'Abbas Askar', 'Mario Pasquato', 'Mirek Giersz']","Machine learning is a powerful technique, becoming increasingly popular in astrophysics. In this paper, we apply machine learning to more than a thousand globular cluster (GC) models simulated as part of the 'MOCCA-Survey Database I' project in order to correlate present-day observable properties with the presence of a subsystem of stellar mass black holes (BHs). The machine learning model is then applied to available observed parameters for Galactic GCs to identify which of them that are most likely to be hosting a sizeable number of BHs and reveal insights into what properties lead to the formation of BH subsystems. With our machine learning model, we were able to shortlist 21 Galactic GCs that are most likely to contain a BH subsystem. We show that the clusters shortlisted by the machine learning classifier include those in which BH candidates have been observed (M22, M10 and NGC 3201) and that our results line up well with independent simulations and previous studies that manually compared simulated GC models with observed properties of Galactic GCs. These results can be useful for observers searching for elusive stellar mass BH candidates in GCs and further our understanding of the role BHs play in GC evolution. In addition, we have released an online tool that allows one to get predictions from our model after they input observable properties.
        ? Less",https://arxiv.org/pdf/1811.06473
30,A classical density functional from machine learning and a convolutional neural network,"['Shang-Chun Lin', 'Martin Oettel']","We use machine learning methods to approximate a classical density functional. As a study case, we choose the model problem of a Lennard Jones fluid in one dimension where there is no exact solution available and training data sets must be obtained from simulations. After separating the excess free energy functional into a ""repulsive"" and an ""attractive"" part, machine learning finds a functional in weighted density form for the attractive part. The density profile at a hard wall shows good agreement for thermodynamic conditions beyond the training set conditions. This also holds for the equation of state if it is evaluated near the training temperature. We discuss the applicability to problems in higher dimensions.
        ? Less",https://arxiv.org/pdf/1811.05728
31,Multiparty Dynamics and Failure Modes for Machine Learning and Artificial Intelligence,['David Manheim'],"Overoptimization failures in machine learning and artificial intelligence systems can involve specification gaming, reward hacking, fragility to distributional shifts, and Goodhart's or Campbell's law. These failure modes are an important challenge in building safe AI systems, and multi-agent systems have additional failure modes that are closely related. These failure modes for multi-agent systems are more complex, more problematic, and less well understood than the single-agent case. They are also already occurring, largely unnoticed. After motivating the discussion with examples from poker-playing AI, the paper explains why these failure modes are in some sense fundamental. Following this, the paper categorizes failure modes, provides definitions, and cites examples for each of: accidental steering, coordination failures, adversarial misalignment, input spoofing and filtering, and goal co-option or direct hacking. The paper then discusses ongoing and potential work on mitigation of these failure modes, and what to expect when these failures continue to proliferate.
        ? Less",https://arxiv.org/pdf/1810.10862
32,SmartChoices: Hybridizing Programming and Machine Learning,"['Victor Carbune', 'Thierry Coppey', 'Alexander Daryin', 'Thomas Deselaers', 'Nikhil Sarda', 'Jay Yagnik']","We present SmartChoices, an approach to making machine learning (ML) a first class citizen in programming languages. There is a growing divide in approaches to building systems: on the one hand, programming leverages human experts to define a system while on the other hand behavior is learned from data in machine learning. We propose to hybridize these two by leveraging the existing concept of a variable and creating a new type called SmartChoice. SmartChoices are akin to native variables with one important distinction: they determine their value using ML when evaluated. We describe the SmartChoices-interface, how it can be used in programming with minimal code changes, and demonstrate that it is an easy to use but still powerful tool by demonstrating improvements over not using ML at all on three algorithmic problems: binary search, QuickSort, and caches. In these three examples, we replace the commonly used heuristics with an ML model entirely encapsulated within a SmartChoice and thus requiring minimal code changes. As opposed to previous work applying ML to algorithmic problems, our proposed approach does not require to drop existing implementations but seamlessly integrates into the standard software development workflow and gives full control to the software developer over how ML methods are applied. Our implementation currently relies on standard Reinforcement Learning (RL) methods. To learn faster, we use the heuristic function, which they are replacing, as an initial function. We show how this initial function can be used to speed up and stabilize learning while providing a safety net that prevents performance to become substantially worse -- allowing for a safe deployment in critical applications.
        ? Less",https://arxiv.org/pdf/1810.00619
33,Application of Machine Learning in Wireless Networks: Key Techniques and Open Issues,"['Yaohua Sun', 'Mugen Peng', 'Yangcheng Zhou', 'Yuzhe Huang', 'Shiwen Mao']","As a key technique for enabling artificial intelligence, machine learning (ML) is capable of solving complex problems without explicit programming. Motivated by its successful applications to many practical tasks like image recognition, both industry and the research community have advocated the applications of ML in wireless communication. This paper comprehensively surveys the recent advances of the applications of ML in wireless communication, which are classified as: resource management in the MAC layer, networking and mobility management in the network layer, and localization in the application layer. The applications in resource management further include power control, spectrum management, backhaul management, cache management, beamformer design and computation resource management, while ML based networking focuses on the applications in clustering, base station switching control, user association and routing. Moreover, literatures in each aspect is organized according to the adopted ML techniques. In addition, several conditions for applying ML to wireless communication are identified to help readers decide whether to use ML and which kind of ML techniques to use, and traditional approaches are also summarized together with their performance comparison with ML based approaches, based on which the motivations of surveyed literatures to adopt ML are clarified. Given the extensiveness of the research area, challenges and unresolved issues are presented to facilitate future studies, where ML based network slicing, infrastructure update to support ML based paradigms, open data sets and platforms for researchers, theoretical guidance for ML implementation and so on are discussed.
        ? Less",https://arxiv.org/pdf/1809.08707
34,Improving Optimization Bounds using Machine Learning: Decision Diagrams meet Deep Reinforcement Learning,"['Quentin Cappart', 'Emmanuel Goutierre', 'David Bergman', 'Louis-Martin Rousseau']","Finding tight bounds on the optimal solution is a critical element of practical solution methods for discrete optimization problems. In the last decade, decision diagrams (DDs) have brought a new perspective on obtaining upper and lower bounds that can be significantly better than classical bounding mechanisms, such as linear relaxations. It is well known that the quality of the bounds achieved through this flexible bounding method is highly reliant on the ordering of variables chosen for building the diagram, and finding an ordering that optimizes standard metrics is an NP-hard problem. In this paper, we propose an innovative and generic approach based on deep reinforcement learning for obtaining an ordering for tightening the bounds obtained with relaxed and restricted DDs. We apply the approach to both the Maximum Independent Set Problem and the Maximum Cut Problem. Experimental results on synthetic instances show that the deep reinforcement learning approach, by achieving tighter objective function bounds, generally outperforms ordering methods commonly used in the literature when the distribution of instances is known. To the best knowledge of the authors, this is the first paper to apply machine learning to directly improve relaxation bounds obtained by general-purpose bounding mechanisms for combinatorial optimization problems.
        ? Less",https://arxiv.org/pdf/1809.03359
35,Analytic continuation via domain-knowledge free machine learning,"['Hongkee Yoon', 'Jae-Hoon Sim', 'Myung Joon Han']","We present a machine-learning approach to a long-standing issue in quantum many-body physics, namely, analytic continuation. This notorious ill-conditioned problem of obtaining spectral function from imaginary time Green's function has been a focus of new method developments for past decades. Here we demonstrate the usefulness of modern machine-learning techniques including convolutional neural networks and the variants of stochastic gradient descent optimiser. Machine-learning continuation kernel is successfully realized without any 'domain-knowledge', which means that any physical 'prior' is not utilized in the kernel construction and the neural networks 'learn' the knowledge solely from 'training'. The outstanding performance is achieved for both insulating and metallic band structure. Our machine-learning-based approach not only provides the more accurate spectrum than the conventional methods in terms of peak positions and heights, but is also more robust against the noise which is the required key feature for any continuation technique to be successful. Furthermore, its computation speed is 10^4^4-10^5^5 times faster than maximum entropy method.
        ? Less",https://arxiv.org/pdf/1806.03841
36,Machine Teaching for Inverse Reinforcement Learning: Algorithms and Applications,"['Daniel S. Brown', 'Scott Niekum']","Inverse reinforcement learning (IRL) infers a reward function from demonstrations, allowing for policy improvement and generalization. However, despite much recent interest in IRL, little work has been done to understand the minimum set of demonstrations needed to teach a specific sequential decision-making task. We formalize the problem of finding maximally informative demonstrations for IRL as a machine teaching problem where the goal is to find the minimum number of demonstrations needed to specify the reward equivalence class of the demonstrator. We extend previous work on algorithmic teaching for sequential decision-making tasks by showing a reduction to the set cover problem which enables an efficient approximation algorithm for determining the set of maximally-informative demonstrations. We apply our proposed machine teaching algorithm to two novel applications: providing a lower bound on the number of queries needed to learn a policy using active IRL and developing a novel IRL algorithm that can learn more efficiently from informative demonstrations than a standard IRL approach.
        ? Less",https://arxiv.org/pdf/1805.07687
37,Learning to Organize Knowledge and Answer Questions with N-Gram Machines,"['Fan Yang', 'Jiazhong Nie', 'William W. Cohen', 'Ni Lao']","Though deep neural networks have great success in natural language processing, they are limited at more knowledge intensive AI tasks, such as open-domain Question Answering (QA). Existing end-to-end deep QA models need to process the entire text after observing the question, and therefore their complexity in responding a question is linear in the text size. This is prohibitive for practical tasks such as QA from Wikipedia, a novel, or the Web. We propose to solve this scalability issue by using symbolic meaning representations, which can be indexed and retrieved efficiently with complexity that is independent of the text size. We apply our approach, called the N-Gram Machine (NGM), to three representative tasks. First as proof-of-concept, we demonstrate that NGM successfully solves the bAbI tasks of synthetic text. Second, we show that NGM scales to large corpus by experimenting on ""life-long bAbI"", a special version of bAbI that contains millions of sentences. Lastly on the WikiMovies dataset, we use NGM to induce latent structure (i.e. schema) and answer questions from natural language Wikipedia text, with only QA pairs as weak supervision.
        ? Less",https://arxiv.org/pdf/1711.06744
