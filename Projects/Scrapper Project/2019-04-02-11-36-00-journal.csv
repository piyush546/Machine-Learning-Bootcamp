,Name,Author,Abstract,Download link
0,An Atomistic Machine Learning Package for Surface Science and Catalysis,"['Martin Hangaard Hansen', 'José A. Garrido Torres', 'Paul C. Jennings', 'Ziyun Wang', 'Jacob R. Boes', 'Osman G. Mamun', 'Thomas Bligaard']","We present work flows and a software module for machine learning model building in surface science and heterogeneous catalysis. This includes fingerprinting atomic structures from 3D structure and/or connectivity information, it includes descriptor selection methods and benchmarks, and it includes active learning frameworks for atomic structure optimization, acceleration of screening studies and for exploration of the structure space of nano particles, which are all atomic structure problems relevant for surface science and heterogeneous catalysis. Our overall goal is to provide a repository to ease machine learning model building for catalysis, to advance the models beyond the chemical intuition of the user and to increase autonomy for exploration of chemical space.
        ? Less",https://arxiv.org/pdf/1904.00904
1,Adversarial-Residual-Coarse-Graining: Applying machine learning theory to systematic molecular coarse-graining,"['Aleksander E. P. Durumeric', 'Gregory A. Voth']","We utilize connections between molecular coarse-graining approaches and implicit generative models in machine learning to describe a new framework for systematic molecular coarse-graining (CG). Focus is placed on the formalism encompassing generative adversarial networks. The resulting method enables a variety of model parameterization strategies, some of which show similarity to previous CG methods. We demonstrate that the resulting framework can rigorously parameterize CG models containing CG sites with no prescribed connection to the reference atomistic system (termed virtual sites); however, this advantage is offset by the lack of explicit CG free energy at the resolution obtained after integration over the virtual CG sites. Computational examples are provided for cases in which these methods ideally return identical parameters as Relative Entropy Minimization (REM) CG but where traditional REM CG is infeasible.
        ? Less",https://arxiv.org/pdf/1904.00871
2,A Novel Malware Detection System Based On Machine Learning and Binary Visualization,"['Irina Baptista', 'Stavros Shiaeles', 'Nicholas Kolokotronis']","The continued evolution and diversity of malware constitutes a major threat in modern systems. It is well proven that security defenses currently available are ineffective to mitigate the skills and imagination of cyber-criminals necessitating the development of novel solutions. Deep learning algorithms and artificial intelligence (AI) are rapidly evolving with remarkable results in many application areas. Following the advances of AI and recognizing the need for efficient malware detection methods, this paper presents a new approach for malware detection based on binary visualization and self-organizing incremental neural networks. The proposed method's performance in detecting malicious payloads in various file types was investigated and the experimental results showed that a detection accuracy of 91.7% and 94.1% was achieved for ransomware in .pdf and .doc files respectively. With respect to other formats of malicious code and other file types, including binaries, the proposed method behaved well with an incremental detection rate that allows efficiently detecting unknown malware at real-time.
        ? Less",https://arxiv.org/pdf/1904.00859
3,Netherlands Dataset: A New Public Dataset for Machine Learning in Seismic Interpretation,"['Reinaldo Mozart Silva', 'Lais Baroni', 'Rodrigo S. Ferreira', 'Daniel Civitarese', 'Daniela Szwarcman', 'Emilio Vital Brazil']","Machine learning and, more specifically, deep learning algorithms have seen remarkable growth in their popularity and usefulness in the last years. This is arguably due to three main factors: powerful computers, new techniques to train deeper networks and larger datasets. Although the first two are readily available in modern computers and ML libraries, the last one remains a challenge for many domains. It is a fact that big data is a reality in almost all fields nowadays, and geosciences are not an exception. However, to achieve the success of general-purpose applications such as ImageNet - for which there are +14 million labeled images for 1000 target classes - we not only need more data, we need more high-quality labeled data. When it comes to the Oil&Gas industry, confidentiality issues hamper even more the sharing of datasets. In this work, we present the Netherlands interpretation dataset, a contribution to the development of machine learning in seismic interpretation. The Netherlands F3 dataset acquisition was carried out in the North Sea, Netherlands offshore. The data is publicly available and contains pos-stack data, 8 horizons and well logs of 4 wells. For the purposes of our machine learning tasks, the original dataset was reinterpreted, generating 9 horizons separating different seismic facies intervals. The interpreted horizons were used to generate approximatelly 190,000 labeled images for inlines and crosslines. Finally, we present two deep learning applications in which the proposed dataset was employed and produced compelling results.
        ? Less",https://arxiv.org/pdf/1904.00770
4,Customer churn prediction in telecom using machine learning and social network analysis in big data platform,"['Abdelrahim Kasem Ahmad', 'Assef Jafar', 'Kadan Aljoumaa']","Customer churn is a major problem and one of the most important concerns for large companies. Due to the direct effect on the revenues of the companies, especially in the telecom field, companies are seeking to develop means to predict potential customer to churn. Therefore, finding factors that increase customer churn is important to take necessary actions to reduce this churn. The main contribution of our work is to develop a churn prediction model which assists telecom operators to predict customers who are most likely subject to churn. The model developed in this work uses machine learning techniques on big data platform and builds a new way of features' engineering and selection. In order to measure the performance of the model, the Area Under Curve (AUC) standard measure is adopted, and the AUC value obtained is 93.3%. Another main contribution is to use customer social network in the prediction model by extracting Social Network Analysis (SNA) features. The use of SNA enhanced the performance of the model from 84 to 93.3% against AUC standard. The model was prepared and tested through Spark environment by working on a large dataset created by transforming big raw data provided by SyriaTel telecom company. The dataset contained all customers' information over 9 months, and was used to train, test, and evaluate the system at SyriaTel. The model experimented four algorithms: Decision Tree, Random Forest, Gradient Boosted Machine Tree ""GBM"" and Extreme Gradient Boosting ""XGBOOST"". However, the best results were obtained by applying XGBOOST algorithm. This algorithm was used for classification in this churn predictive model.
        ? Less",https://arxiv.org/pdf/1904.00690
5,Adaptive Bayesian Linear Regression for Automated Machine Learning,"['Weilin Zhou', 'Frederic Precioso']","To solve a machine learning problem, one typically needs to perform data preprocessing, modeling, and hyperparameter tuning, which is known as model selection and hyperparameter optimization.The goal of automated machine learning (AutoML) is to design methods that can automatically perform model selection and hyperparameter optimization without human interventions for a given dataset. In this paper, we propose a meta-learning method that can search for a high-performance machine learning pipeline from the predefined set of candidate pipelines for supervised classification datasets in an efficient way by leveraging meta-data collected from previous experiments. More specifically, our method combines an adaptive Bayesian regression model with a neural network basis function and the acquisition function from Bayesian optimization. The adaptive Bayesian regression model is able to capture knowledge from previous meta-data and thus make predictions of the performances of machine learning pipelines on a new dataset. The acquisition function is then used to guide the search of possible pipelines based on the predictions.The experiments demonstrate that our approach can quickly identify high-performance pipelines for a range of test datasets and outperforms the baseline methods.
        ? Less",https://arxiv.org/pdf/1904.00577
6,Fourier Transform Approach to Machine Learning,['Soheil Mehrabkhani'],"We propose a supervised learning algorithm for machine learning applications. Contrary to the model developing in the classical methods, which treat training, validation, and test as separate steps, in the presented approach, there is a unified training and evaluating procedure based on an iterative band filtering by the use of a fast Fourier transform. The presented approach does not apply the method of least squares, thus, basically typical ill-conditioned matrices do not occur at all. The optimal model results from the convergence of the performance metric, which automatically prevents the usual underfitting and overfitting problems. The algorithm capability is investigated for noisy data, and the obtained result demonstrates a reliable and powerful machine learning approach beyond the typical limits of the classical methods.
        ? Less",https://arxiv.org/pdf/1904.00368
7,SysML'19 demo: customizable and reusable Collective Knowledge pipelines to automate and reproduce machine learning experiments,['Grigori Fursin'],"Reproducing, comparing and reusing results from machine learning and systems papers is a very tedious, ad hoc and time-consuming process. I will demonstrate how to automate this process using open-source, portable, customizable and CLI-based Collective Knowledge workflows and pipelines developed by the community. I will help participants run several real-world non-virtualized CK workflows from the SysML'19 conference, companies (General Motors, Arm) and MLPerf benchmark to automate benchmarking and co-design of efficient software/hardware stacks for machine learning workloads. I hope that our approach will help authors reduce their effort when sharing reusable and extensible research artifacts while enabling artifact evaluators to automatically validate experimental results from published papers in a standard and portable way.
        ? Less",https://arxiv.org/pdf/1904.00324
8,NetKet: A Machine Learning Toolkit for Many-Body Quantum Systems,"['Giuseppe Carleo', 'Kenny Choo', 'Damian Hofmann', 'James E. T. Smith', 'Tom Westerhout', 'Fabien Alet', 'Emily J. Davis', 'Stavros Efthymiou', 'Ivan Glasser', 'Sheng-Hsuan Lin', 'Marta Mauri', 'Guglielmo Mazzola', 'Christian B. Mendl', 'Evert van Nieuwenburg', ""Ossian O'Reilly"", 'Hugo Théveniaut', 'Giacomo Torlai', 'Alexander Wietek']","We introduce NetKet, a comprehensive open source framework for the study of many-body quantum systems using machine learning techniques. The framework is built around a general and flexible implementation of neural-network quantum states, which are used as a variational ansatz for quantum wave functions. NetKet provides algorithms for several key tasks in quantum many-body physics and quantum technology, namely quantum state tomography, supervised learning from wave-function data, and ground state searches for a wide range of customizable lattice models. Our aim is to provide a common platform for open research and to stimulate the collaborative development of computational methods at the interface of machine learning and many-body physics.
        ? Less",https://arxiv.org/pdf/1904.00031
9,Open Problems in Engineering Machine Learning Systems and the Quality Model,"['Hiroshi Kuwajima', 'Hirotoshi Yasuoka', 'Toshihiro Nakae']","Fatal accidents are a major issue hindering the wide acceptance of safety-critical systems that use machine learning and deep learning models, such as automated driving vehicles. To use machine learning in a safety-critical system, it is necessary to demonstrate the safety and security of the system to society through the engineering process. However, there have been no such total concepts or frameworks established for these systems that have been widely accepted, and needs or open problems are not organized in a way researchers can select a theme and work on. The key to using a machine learning model in a deductively engineered system, developed in a rigorous development lifecycle consisting of requirement, design, and verification, cf. V-Model, is decomposing the data-driven training of machine-learning models into requirement, design, and verification, especially for machine learning models used in safety-critical systems. In this study, we identify, classify, and explore the open problems in engineering (safety-critical) machine learning systems, i.e., requirement, design, and verification of machine learning models and systems, as well as related works and research directions, using automated driving vehicles as an example. We also discuss the introduction of machine-learning models into a conventional system quality model such as SQuARE to study the quality model for machine learning systems.
        ? Less",https://arxiv.org/pdf/1904.00001
10,Informed Machine Learning - Towards a Taxonomy of Explicit Integration of Knowledge into Machine Learning,"['Laura von Rueden', 'Sebastian Mayer', 'Jochen Garcke', 'Christian Bauckhage', 'Jannis Schuecker']","Despite the great successes of machine learning, it can have its limits when dealing with insufficient training data.A potential solution is to incorporate additional knowledge into the training process which leads to the idea of informed machine learning. We present a research survey and structured overview of various approaches in this field. We aim to establish a taxonomy which can serve as a classification framework that considers the kind of additional knowledge, its representation,and its integration into the machine learning pipeline. The evaluation of numerous papers on the bases of the taxonomy uncovers key methods in this field.
        ? Less",https://arxiv.org/pdf/1903.12394
11,A Machine Learning Framework for Biometric Authentication using Electrocardiogram,"['Song-Kyoo Kim', 'Chan Yeob Yeun', 'Ernesto Damiani', 'Nai-Wei Lo']","This paper introduces a framework for how to appropriately adopt and adjust Machine Learning (ML) techniques used to construct Electrocardiogram (ECG) based biometric authentication schemes. The proposed framework can help investigators and developers on ECG based biometric authentication mechanisms define the boundaries of required datasets and get training data with good quality. To determine the boundaries of datasets, use case analysis is adopted. Based on various application scenarios on ECG based authentication, three distinct use cases (or authentication categories) are developed. With more qualified training data given to corresponding machine learning schemes, the precision on ML-based ECG biometric authentication mechanisms is increased in consequence. ECG time slicing technique with the R-peak anchoring is utilized in this framework to acquire ML training data with good quality. In the proposed framework four new measure metrics are introduced to evaluate the quality of ML training and testing data. In addition, a Matlab toolbox, containing all proposed mechanisms, metrics and sample data with demonstrations using various ML techniques, is developed and publicly available for further investigation. For developing ML-based ECG biometric authentication, the proposed framework can guide researchers to prepare the proper ML setups and the ML training datasets along with three identified user case scenarios. For researchers adopting ML techniques to design new schemes in other research domains, the proposed framework is still useful for generating ML-based training and testing datasets with good quality and utilizing new measure metrics.
        ? Less",https://arxiv.org/pdf/1903.12340
12,Using Latent Class Analysis to Identify ARDS Sub-phenotypes for Enhanced Machine Learning Predictive Performance,"['Tony Wang', 'Tim Tschampel', 'Emilia Apostolova', 'Tom Velez']","In this work, we utilize Machine Learning for early recognition of patients at high risk of acute respiratory distress syndrome (ARDS), which is critical for successful prevention strategies for this devastating syndrome. The difficulty in early ARDS recognition stems from its complex and heterogenous nature. In this study, we integrate knowledge of the heterogeneity of ARDS patients into predictive model building. Using MIMIC-III data, we first apply latent class analysis (LCA) to identify homogeneous sub-groups in the ARDS population, and then build predictive models on the partitioned data. The results indicate that significantly improved performances of prediction can be obtained for two of the three identified sub-phenotypes of ARDS. Experiments suggests that identifying sub-phenotypes is beneficial for building predictive model for ARDS.
        ? Less",https://arxiv.org/pdf/1903.12127
13,Building Automated Survey Coders via Interactive Machine Learning,"['Andrea Esuli', 'Alejandro Moreo', 'Fabrizio Sebastiani']","Software systems trained via machine learning to automatically classify open-ended answers (a.k.a. verbatims) are by now a reality. Still, their adoption in the survey coding industry has been less widespread than it might have been. Among the factors that have hindered a more massive takeup of this technology are the effort involved in manually coding a sufficient amount of training data, the fact that small studies do not seem to justify this effort, and the fact that the process needs to be repeated anew when brand new coding tasks arise. In this paper we will argue for an approach to building verbatim classifiers that we will call ""Interactive Learning"", and that addresses all the above problems. We will show that, for the same amount of training effort, interactive learning delivers much better coding accuracy than standard ""non-interactive"" learning. This is especially true when the amount of data we are willing to manually code is small, which makes this approach attractive also for small-scale studies. Interactive learning also lends itself to reusing previously trained classifiers for dealing with new (albeit related) coding tasks. Interactive learning also integrates better in the daily workflow of the survey specialist, and delivers a better user experience overall.
        ? Less",https://arxiv.org/pdf/1903.12110
14,"Radiological images and machine learning: trends, perspectives, and prospects","['Zhenwei Zhang', 'Ervin Sejdic']","The application of machine learning to radiological images is an increasingly active research area that is expected to grow in the next five to ten years. Recent advances in machine learning have the potential to recognize and classify complex patterns from different radiological imaging modalities such as x-rays, computed tomography, magnetic resonance imaging and positron emission tomography imaging. In many applications, machine learning based systems have shown comparable performance to human decision-making. The applications of machine learning are the key ingredients of future clinical decision making and monitoring systems. This review covers the fundamental concepts behind various machine learning techniques and their applications in several radiological imaging areas, such as medical image segmentation, brain function studies and neurological disease diagnosis, as well as computer-aided systems, image registration, and content-based image retrieval systems. Synchronistically, we will briefly discuss current challenges and future directions regarding the application of machine learning in radiological imaging. By giving insight on how take advantage of machine learning powered applications, we expect that clinicians can prevent and diagnose diseases more accurately and efficiently.
        ? Less",https://arxiv.org/pdf/1903.11726
15,Machine learning approaches in Detecting the Depression from Resting-state Electroencephalogram (EEG): A Review Study,['Milena Cukic Radenkovic'],"In this paper, we aimed at reviewing several different approaches present today in the search for more accurate diagnostic and treatment management in mental healthcare. Our focus is on mood disorders, and in particular on the major depressive disorder (MDD). We are reviewing and discussing findings based on neuroimaging studies (MRI and fMRI) first to get the impression of the body of knowledge about the anatomical and functional differences in depression. Then, we are focusing on less expensive data-driven approach, applicable for everyday clinical practice, in particular, those based on electroencephalographic (EEG) recordings. Among those studies utilizing EEG, we are discussing a group of applications used for detecting of depression based on the resting state EEG (detection studies) and interventional studies (using stimulus in their protocols or aiming to predict the outcome of therapy). We conclude with a discussion and review of guidelines to improve the reliability of developed models that could serve improvement of diagnostic of depression in psychiatry.
        ? Less",https://arxiv.org/pdf/1903.11454
16,Augmented Ultrasonic Data for Machine Learning,"['Iikka Virkkunen', 'Tuomas Koskinen', 'Oskari Jessen-Juhler', 'Jari Rinta-Aho']","Flaw detection in non-destructive testing, especially in complex signals like ultrasonic data, has thus far relied heavily on the expertise and judgement of trained human inspectors. While automated systems have been used for a long time, these have mostly been limited to using simple decision automation, such as signal amplitude threshold. The recent advances in various machine learning algorithms have solved many similarly difficult classification problems, that have previously been considered intractable. For non-destructive testing, encouraging results have already been reported in the open literature, but the use of machine learning is still very limited in NDT applications in the field. Key issue hindering their use, is the limited availability of representative flawed data-sets to be used for training. In the present paper, we develop modern, very deep convolutional network to detect flaws from phased-array ultrasonic data. We make extensive use of data augmentation to enhance the initially limited raw data and to aid learning. The data augmentation utilizes virtual flaws - a technique, that has successfully been used in training human inspectors and is soon to be used in nuclear inspection qualification. The results from the machine learning classifier are compared to human performance. We show, that using sophisticated data augmentation, modern deep learning networks can be trained to achieve superhuman performance by significant margin.
        ? Less",https://arxiv.org/pdf/1903.11399
17,Machine Learning for Pricing American Options in High Dimension,"['Ludovic Goudenège', 'Andrea Molent', 'Antonino Zanette']","In this paper we propose an efficient method to compute the price of American basket options, based on Machine Learning and Monte Carlo simulations. Specifically, the options we consider are written on a basket of assets, each of them following a Black-Scholes dynamics. The method we propose is a backward dynamic programming algorithm which considers a finite number of uniformly distributed exercise dates. On these dates, the value of the option is computed as the maximum between the exercise value and the continuation value, which is approximated via Gaussian Process Regression. Specifically, we consider a finite number of points, each of them representing the values reached by the underlying at a certain time. First of all, we compute the continuation value only for these points by means of Monte Carlo simulations and then we employ Gaussian Process Regression to approximate the whole continuation value function. Numerical tests show that the algorithm is fast and reliable and it can handle also American options on very large baskets of assets, overcoming the problem of the curse of dimensionality.
        ? Less",https://arxiv.org/pdf/1903.11275
18,Data Science and Digital Systems: The 3Ds of Machine Learning Systems Design,['Neil D. Lawrence'],"Machine learning solutions, in particular those based on deep learning methods, form an underpinning of the current revolution in ""artificial intelligence"" that has dominated popular press headlines and is having a significant influence on the wider tech agenda. Here we give an overview of the 3Ds of ML systems design: Data, Design and Deployment. By considering the 3Ds we can move towards \emph{data first} design.
        ? Less",https://arxiv.org/pdf/1903.11241
19,Machine Learning Reveals the State of Intermittent Frictional Dynamics in a Sheared Granular Fault,"['C. X. Ren', 'O. Dorostkar', 'B. Rouet-Leduc', 'C. Hulbert', 'D. Strebel', 'R. A. Guyer', 'P. A. Johnson', 'J. Carmeliet']","Seismogenic plate boundaries are presumed to behave in a similar manner to a densely packed granular medium, where fault and blocks systems rapidly rearrange the distribution of forces within themselves, as particles do in slowly sheared granular systems. We use machine learning and show that statistical features of velocity signals from individual particles in a simulated sheared granular fault contain information regarding the instantaneous global state of intermittent frictional stick-slip dynamics. We demonstrate that combining features built from the signals of more particles can improve the accuracy of the global model, and discuss the physical basis behind decrease in error. We show that the statistical features such as median and higher moments of the signals that represent the particle displacement in the direction of shearing are among the best predictive features. Our work provides novel insights into the applications of machine learning in studying frictional processes that take place in geophysical systems.
        ? Less",https://arxiv.org/pdf/1903.11157
20,Cross-Modal Data Programming Enables Rapid Medical Machine Learning,"['Jared Dunnmon', 'Alexander Ratner', 'Nishith Khandwala', 'Khaled Saab', 'Matthew Markert', 'Hersh Sagreiya', 'Roger Goldman', 'Christopher Lee-Messer', 'Matthew Lungren', 'Daniel Rubin', 'Christopher Ré']","Labeling training datasets has become a key barrier to building medical machine learning models. One strategy is to generate training labels programmatically, for example by applying natural language processing pipelines to text reports associated with imaging studies. We propose cross-modal data programming, which generalizes this intuitive strategy in a theoretically-grounded way that enables simpler, clinician-driven input, reduces required labeling time, and improves with additional unlabeled data. In this approach, clinicians generate training labels for models defined over a target modality (e.g. images or time series) by writing rules over an auxiliary modality (e.g. text reports). The resulting technical challenge consists of estimating the accuracies and correlations of these rules; we extend a recent unsupervised generative modeling technique to handle this cross-modal setting in a provably consistent way. Across four applications in radiography, computed tomography, and electroencephalography, and using only several hours of clinician time, our approach matches or exceeds the efficacy of physician-months of hand-labeling with statistical significance, demonstrating a fundamentally faster and more flexible way of building machine learning models in medicine.
        ? Less",https://arxiv.org/pdf/1903.11101
21,Generative Tensor Network Classification Model for Supervised Machine Learning,"['Zheng-Zhi Sun', 'Cheng Peng', 'Ding Liu', 'Shi-Ju Ran', 'Gang Su']","Tensor network (TN) has recently triggered extensive interests in developing machine-learning models in quantum many-body Hilbert space. Here we purpose a generative TN classification (GTNC) approach for supervised learning. The strategy is to train the generative TN for each class of the samples to construct the classifiers. The classification is implemented by comparing the distance in the many-body Hilbert space. The numerical experiments by GTNC show impressive performance on the MNIST and Fashion-MNIST dataset. The testing accuracy is competitive to the state-of-the-art convolutional neural network while higher than the naive Bayes classifier (a generative classifier) and support vector machine. Moreover, GTNC is more efficient than the existing TN models that are in general discriminative. By investigating the distances in the many-body Hilbert space, we find that (a) the samples are naturally clustering in such a space; and (b) bounding the bond dimensions of the TN's to finite values corresponds to removing redundant information in the image recognition. These two characters make GTNC an adaptive and universal model of excellent performance.
        ? Less",https://arxiv.org/pdf/1903.10742
22,Interoperability and machine-to-machine translation model with mappings to machine learning tasks,"['Jacob Nilsson', 'Fredrik Sandin', 'Jerker Delsing']","Modern large-scale automation systems integrate thousands to hundreds of thousands of physical sensors and actuators. Demands for more flexible reconfiguration of production systems and optimization across different information models, standards and legacy systems challenge current system interoperability concepts. Automatic semantic translation across information models and standards is an increasingly important problem that needs to be addressed to fulfill these demands in a cost-efficient manner under constraints of human capacity and resources in relation to timing requirements and system complexity. Here we define a translator-based operational interoperability model for interacting cyber-physical systems in mathematical terms, which includes system identification and ontology-based translation as special cases. We present alternative mathematical definitions of the translator learning task and mappings to similar machine learning tasks and solutions based on recent developments in machine learning. Possibilities to learn translators between artefacts without a common physical context, for example in simulations of digital twins and across layers of the automation pyramid are briefly discussed.
        ? Less",https://arxiv.org/pdf/1903.10735
23,Competence-based Curriculum Learning for Neural Machine Translation,"['Emmanouil Antonios Platanios', 'Otilia Stretcu', 'Graham Neubig', 'Barnabas Poczos', 'Tom M. Mitchell']","Current state-of-the-art NMT systems use large neural networks that are not only slow to train, but also often require many heuristics and optimization tricks, such as specialized learning rate schedules and large batch sizes. This is undesirable as it requires extensive hyperparameter tuning. In this paper, we propose a curriculum learning framework for NMT that reduces training time, reduces the need for specialized heuristics or large batch sizes, and results in overall better performance. Our framework consists of a principled way of deciding which training samples are shown to the model at different times during training, based on the estimated difficulty of a sample and the current competence of the model. Filtering training samples in this manner prevents the model from getting stuck in bad local optima, making it converge faster and reach a better solution than the common approach of uniformly sampling training examples. Furthermore, the proposed method can be easily applied to existing NMT models by simply modifying their input data pipelines. We show that our framework can help improve the training time and the performance of both recurrent neural network models and Transformers, achieving up to a 70% decrease in training time, while at the same time obtaining accuracy improvements of up to 2.2 BLEU.
        ? Less",https://arxiv.org/pdf/1903.09848
24,Machines listening to music: the role of signal representations in learning from music,"['Roswitha Bammer', 'Anna Breger', 'Monika Dörfler', 'Pavol Harar', 'Zdenek Smekal']","Recent, extremely successful methods in deep learning, such as convolutional neural networks (CNNs) have originated in machine learning for images. When applied to music signals and related music information retrieval (MIR) problems, researchers often apply standard FFT-based signal processing methods in order to create an image from the raw audio data. The impact of this basic signal processing step on the final outcome of the MIR task has not been widely studied and is not well understood. In this contribution, we study Gabor Scattering and a new representation, namely Mel Scattering. Furthermore, we suggest an alternative enhancement of the loss function that uses transformed representations of the output data to incorporate additional available information. We show how applying various different signal analysis methods can lead to useful invariances and improve the overall performance in MIR problems by reducing the amount of necessary training data or the necessity of augmentation.
        ? Less",https://arxiv.org/pdf/1903.08950
25,Machine learning non-Markovian quantum dynamics,"['I. A. Luchnikov', 'S. V. Vintskevich', 'D. A. Grigoriev', 'S. N. Filippov']","Machine learning methods have proved to be useful for the recognition of patterns in statistical data. The measurement outcomes are intrinsically random in quantum physics, however they do have a pattern when the measurements are performed successively on an open quantum system. This pattern is due to the system-environment interaction and contains information about the relaxation rates as well as non-Markovian memory effects. Here we develop a method to extract the information about the unknown environment from a series of single-shot measurements on the system (without resorting to the process tomography). The method is based on embedding the non-Markovian system dynamics into a Markovian dynamics of the system and the effective reservoir of finite dimension. The generator of Markovian embedding is learned by the maximum likelihood estimation. We verify the method by comparing its prediction with an exactly solvable non-Markovian dynamics. The developed algorithm to learn unknown quantum environments enables one to efficiently control and manipulate quantum systems.
        ? Less",https://arxiv.org/pdf/1902.07019
26,Towards Machine Learning Induction,['Yutaka Nagashima'],"Induction lies at the heart of mathematics and computer science. However, automated theorem proving of inductive problems is still limited in its power. In this abstract, we first summarize our progress in automating inductive theorem proving for Isabelle/HOL. Then, we present MeLoId, our approach to suggesting promising applications of induction without completing a proof search.
        ? Less",https://arxiv.org/pdf/1812.04088
27,Machine Learning-based Link Fault Identification and Localization in Complex Networks,"['Srinikethan Madapuzi Srinivasan', 'Tram Truong-Huu', 'Mohan Gurusamy']","With the proliferation of network devices and rapid development in information technology, networks such as Internet of Things are increasing in size and becoming more complex with heterogeneous wired and wireless links. In such networks, link faults may result in a link disconnection without immediate replacement or a link reconnection, e.g., a wireless node changes its access point. Identifying whether a link disconnection or a link reconnection has occurred and localizing the failed link become a challenging problem. An active probing approach requires a long time to probe the network by sending signaling messages on different paths, thus incurring significant communication delay and overhead. In this paper, we adopt a passive approach and develop a three-stage machine learning-based technique, namely ML-LFIL that identifies and localizes link faults by analyzing the measurements captured from the normal traffic flows, including aggregate flow rate, end-to-end delay and packet loss. ML-LFIL learns the traffic behavior in normal working conditions and different link fault scenarios. We train the learning model using support vector machine, multi-layer perceptron and random forest. We implement ML-LFIL and carry out extensive experiments using Mininet platform. Performance studies show that ML-LFIL achieves high accuracy while requiring much lower fault localization time compared to the active probing approach.
        ? Less",https://arxiv.org/pdf/1812.03650
28,A Machine-Learning Phase Classification Scheme for Anomaly Detection in Signals with Periodic Characteristics,"['Lia Ahrens', 'Julian Ahrens', 'Hans D. Schotten']","In this paper we propose a novel machine-learning method for anomaly detection applicable to data with periodic characteristics where randomly varying period lengths are explicitly allowed. A multi-dimensional time series analysis is conducted by training a data-adapted classifier consisting of deep convolutional neural networks performing phase classification. The entire algorithm including data pre-processing, period detection, segmentation, and even dynamic adjustment of the neural networks is implemented for fully automatic execution. The proposed method is evaluated on three example datasets from the areas of cardiology, intrusion detection, and signal processing, presenting reasonable performance.
        ? Less",https://arxiv.org/pdf/1811.12119
29,On the dissection of degenerate cosmologies with machine learning,"['Julian Merten', 'Carlo Giocoli', 'Marco Baldi', 'Massimo Meneghetti', 'Austin Peel', 'Florian Lalande', 'Jean-Luc Starck', 'Valeria Pettorino']","Based on the DUSTGRAIN-pathfinder suite of simulations, we investigate observational degeneracies between nine models of modified gravity and massive neutrinos. Three types of machine learning techniques are tested for their ability to discriminate lensing convergence maps by extracting dimensional reduced representations of the data. Classical map descriptors such as the power spectrum, peak counts and Minkowski functionals are combined into a joint feature vector and compared to the descriptors and statistics that are common to the field of digital image processing. To learn new features directly from the data we use a Convolutional Neural Network (CNN). For the mapping between feature vectors and the predictions of their underlying model, we implement two different classifiers; one based on a nearest-neighbour search and one that is based on a fully connected neural network. We find that the neural network provides a much more robust classification than the nearest-neighbour approach and that the CNN provides the most discriminating representation of the data. It achieves the cleanest separation between the different models and the highest classification success rate of 59% for a single source redshift. Once we perform a tomographic CNN analysis, the total classification accuracy increases significantly to 76% with no observational degeneracies remaining. Visualising the filter responses of the CNN at different network depths provides us with the unique opportunity to learn from very complex models and to understand better why they perform so well.
        ? Less",https://arxiv.org/pdf/1810.11027
30,Machine learning clustering technique applied to powder X-ray diffraction patterns to distinguish alloy substitutions,"['Keishu Utimula', 'Rutchapon Hunkao', 'Masao Yano', 'Hiroyuki Kimoto', 'Kenta Hongo', 'Shogo Kawaguchi', 'Sujin Suwanna', 'Ryo Maezono']","We applied the clustering technique using DTW (dynamic time wrapping) analysis to XRD (X-ray diffraction) spectrum patterns in order to identify the microscopic structures of substituents introduced in the main phase of magnetic alloys. The clustering is found to perform well to identify the concentrations of the substituents with successful rates (around 90%). The sufficient performance is attributed to the nature of DTW processing to filter out irrelevant informations such as the peak intensities (due to the incontrollability of diffraction conditions in polycrystalline samples) and the uniform shift of peak positions (due to the thermal expansions of lattices).
        ? Less",https://arxiv.org/pdf/1810.03972
31,Multi-task Learning with Sample Re-weighting for Machine Reading Comprehension,"['Yichong Xu', 'Xiaodong Liu', 'Yelong Shen', 'Jingjing Liu', 'Jianfeng Gao']","We propose a multi-task learning framework to learn a joint Machine Reading Comprehension (MRC) model that can be applied to a wide range of MRC tasks in different domains. Inspired by recent ideas of data selection in machine translation, we develop a novel sample re-weighting scheme to assign sample-specific weights to the loss. Empirical study shows that our approach can be applied to many existing MRC models. Combined with contextual representations from pre-trained language models (such as ELMo), we achieve new state-of-the-art results on a set of MRC benchmark datasets. We release our code at https://github.com/xycforgithub/MultiTask-MRC.
        ? Less",https://arxiv.org/pdf/1809.06963
32,Data-driven polynomial chaos expansion for machine learning regression,"['E. Torre', 'S. Marelli', 'P. Embrechts', 'B. Sudret']","We present a regression technique for data-driven problems based on polynomial chaos expansion (PCE). PCE is a popular technique in the field of uncertainty quantification (UQ), where it is typically used to replace a runnable but expensive computational model subject to random inputs with an inexpensive-to-evaluate polynomial function. The metamodel obtained enables a reliable estimation of the statistics of the output, provided that a suitable probabilistic model of the input is available. Machine learning (ML) regression is a research field that focuses on providing purely data-driven input-output maps, with the focus on pointwise prediction accuracy. We show that a PCE metamodel purely trained on data can yield pointwise predictions whose accuracy is comparable to that of other ML regression models, such as neural networks and support vector machines. The comparisons are performed on benchmark datasets available from the literature. The methodology also enables the quantification of the output uncertainties, and is robust to noise. Furthermore, it enjoys additional desirable properties, such as good performance for small training sets and simplicity of construction, with only little parameter tuning required.
        ? Less",https://arxiv.org/pdf/1808.03216
33,Machine Learning in Electronic Quantum Matter Imaging Experiments,"['Yi Zhang', 'A. Mesaros', 'K. Fujita', 'S. D. Edkins', 'M. H. Hamidian', ""K. Ch'ng"", 'H. Eisaki', 'S. Uchida', 'J. C. Séamus Davis', 'E. Khatami', 'Eun-Ah Kim']","Essentials of the scientific discovery process have remained largely unchanged for centuries: systematic human observation of natural phenomena is used to form hypotheses that, when validated through experimentation, are generalized into established scientific theory. Today, however, we face major challenges because automated instrumentation and large-scale data acquisition are generating data sets of such volume and complexity as to defy human analysis. Radically different scientific approaches are needed, with machine learning (ML) showing great promise, not least for materials science research. Hence, given recent advances in ML analysis of synthetic data representing electronic quantum matter (EQM), the next challenge is for ML to engage equivalently with experimental data. For example, atomic-scale visualization of EQM yields arrays of complex electronic structure images, that frequently elude effective analyses. Here we report development and training of an array of artificial neural networks (ANN) designed to recognize different types of hypothesized order hidden in EQM image-arrays. These ANNs are used to analyze an experimentally-derived EQM image archive from carrier-doped cuprate Mott insulators. Throughout these noisy and complex data, the ANNs discover the existence of a lattice-commensurate, four-unit-cell periodic, translational-symmetry-breaking EQM state. Further, the ANNs find these phenomena to be unidirectional, revealing a coincident nematic EQM state. Strong-coupling theories of electronic liquid crystals are congruent with all these observations.
        ? Less",https://arxiv.org/pdf/1808.00479
34,A Robust Multi-Batch L-BFGS Method for Machine Learning,"['Albert S. Berahas', 'Martin Taká?']","This paper describes an implementation of the L-BFGS method designed to deal with two adversarial situations. The first occurs in distributed computing environments where some of the computational nodes devoted to the evaluation of the function and gradient are unable to return results on time. A similar challenge occurs in a multi-batch approach in which the data points used to compute function and gradients are purposely changed at each iteration to accelerate the learning process. Difficulties arise because L-BFGS employs gradient differences to update the Hessian approximations, and when these gradients are computed using different data points the updating process can be unstable. This paper shows how to perform stable quasi-Newton updating in the multi-batch setting, studies the convergence properties for both convex and nonconvex functions, and illustrates the behavior of the algorithm in a distributed computing platform on binary classification logistic regression and neural network training problems that arise in machine learning.
        ? Less",https://arxiv.org/pdf/1707.08552
35,Robust Wasserstein Profile Inference and Applications to Machine Learning,"['Jose Blanchet', 'Yang Kang', 'Karthyek Murthy']","We show that several machine learning estimators, including square-root LASSO (Least Absolute Shrinkage and Selection) and regularized logistic regression can be represented as solutions to distributionally robust optimization (DRO) problems. The associated uncertainty regions are based on suitably defined Wasserstein distances. Hence, our representations allow us to view regularization as a result of introducing an artificial adversary that perturbs the empirical distribution to account for out-of-sample effects in loss estimation. In addition, we introduce RWPI (Robust Wasserstein Profile Inference), a novel inference methodology which extends the use of methods inspired by Empirical Likelihood to the setting of optimal transport costs (of which Wasserstein distances are a particular case). We use RWPI to show how to optimally select the size of uncertainty regions, and as a consequence, we are able to choose regularization parameters for these machine learning estimators without the use of cross validation. Numerical experiments are also given to validate our theoretical findings.
        ? Less",https://arxiv.org/pdf/1610.05627
